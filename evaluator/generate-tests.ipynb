{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973d476f-da88-4847-8b0d-8e495d77993f",
   "metadata": {},
   "source": [
    "# Generate Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d762ca93-e6d8-4b1d-883b-d42b6ee45721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d957b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dd184b-b113-42fe-b10e-8c4ceb21c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = model.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c86b7a-7873-47d4-907e-0fbe1aeab1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import os\n",
    "\n",
    "client = MilvusClient(uri=os.getenv('MILVUS_ADDR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de8730-1b31-492b-b8fa-78c0e47ca82a",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591f24b5-c7ce-4083-a3c8-880fb76542c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, collection, threshold=0.5, limit=3):\n",
    "    query_vectors = embedding_fn.encode_queries([query])\n",
    "    results = client.search(\n",
    "        collection_name=collection,  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=limit,  # number of returned entities\n",
    "        output_fields=[\"text\", \"metadata\"],  # specifies fields to be returned\n",
    "        # filter=\"subject == 'history'\", # metadata filtering\n",
    "    )[0]\n",
    "    \n",
    "    distanceThreshold = threshold\n",
    "    \n",
    "    return [\n",
    "        result\n",
    "        for result in results if result['distance'] >= distanceThreshold\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c6be-5633-41ab-857d-67dcd958b533",
   "metadata": {},
   "source": [
    "# Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620f7a1b-a3a1-44f5-a9c1-bf8f5fd1868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import PyPDFParser\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=\"../datasets\",\n",
    "        glob=\"**/*.pdf\",\n",
    "    ),\n",
    "    blob_parser=PyPDFParser(),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8576b9aa-1f5e-443e-9dee-111c56a3130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ba567f-6f66-4cd4-8bcc-9fc32277029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200, # Overlap to maintain context between chunks\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3c96c7-b653-487f-bad6-c370cd9e7d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(docs)\n",
    "data = []\n",
    "\n",
    "is_debug = False\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    vector = embedding_fn.encode_documents([chunk.page_content])\n",
    "    d = {\n",
    "        \"id\": i,\n",
    "        \"vector\": vector[0],\n",
    "        \"text\": chunk.page_content,\n",
    "        \"metadata\": chunk.metadata,\n",
    "    }\n",
    "    data.append(d)\n",
    "    is_debug and print(i)\n",
    "    is_debug and print(chunk.page_content)\n",
    "    is_debug and pp(chunk.metadata)\n",
    "    is_debug and print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e931d1a9-0158-4ce9-8496-90c3ce32da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdf_collection']\n"
     ]
    }
   ],
   "source": [
    "client.has_collection(collection_name=\"pdf_collection\") and client.drop_collection(collection_name=\"pdf_collection\")\n",
    "client.create_collection(\n",
    "    collection_name=\"pdf_collection\",\n",
    "    dimension=embedding_fn.dim, \n",
    ")\n",
    "pp(client.list_collections())\n",
    "res = client.insert(collection_name=\"pdf_collection\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1c804",
   "metadata": {},
   "source": [
    "# Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50190723-5cb6-47d2-8aa7-884183987742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ollama'\n"
     ]
    }
   ],
   "source": [
    "from llm import ModelGardenLLM\n",
    "from embeddings import ModelGardenEmbeddings, OllamaRagasEmbeddings\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "\n",
    "llm_type = os.getenv('LLM_TYPE')\n",
    "model = os.getenv('MODEL_GARDEN_MODEL')\n",
    "embedding = os.getenv('EMBEDDING_MODEL')\n",
    "\n",
    "if llm_type == \"model_garden\":\n",
    "    url = os.getenv('MODEL_GARDEN_URL')\n",
    "    embed_url = os.getenv('EMBEDDING_URL')\n",
    "    llm = ModelGardenLLM(api_url=url, model=model)\n",
    "    embeds = ModelGardenEmbeddings(api_url=embed_url, model=embedding)\n",
    "elif llm_type == \"ollama\":\n",
    "    llm = OllamaLLM(model=model, temperature=0.4)\n",
    "    embeds = OllamaRagasEmbeddings(model=embedding)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported LLM type: {llm_type}\")\n",
    "pp(llm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2018f3-93fc-4ccf-a75e-e27541f4659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b56c28318a43beb0546f6809510e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1867eacde72c463fb7bc9a56016c5321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acff15a1fc824570b425b14188c6abea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying EmbeddingExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamdembo/projects/github.com/walbertus/rag-pipeline-poc/evaluator/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py:202: UserWarning: Using sync embedding model OllamaRagasEmbeddings in async context. This may impact performance. Consider using an async-compatible embedding model for better performance.\n",
      "  property_name, property_value = await self.extract(node)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9272678788954b44b4cd436060211e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying ThemesExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037527597d3243ffb41f8ee5d9242989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying NERExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2feb386ccca94525a4c7e2e6048bc7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CosineSimilarityBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fda6474e4f45fcbdbbcbee649a00b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a180672957e488892814a8020a77682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ba7660601d4201a9a37ba71c83161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e8327d65284c578382d79fe447e3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=llm, embedding_model=embeds)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=1)\n",
    "dataset.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e90375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA AR...</td>\n",
       "      <td>[H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA A...</td>\n",
       "      <td>The logging infrastructure was designed to sca...</td>\n",
       "      <td>Amina</td>\n",
       "      <td>MISSPELLED</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How d'd BARITO dev'pmt addr'ss ELK scal'g iss'...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nH Ho ow w  w we e  b bu ui il lt t...</td>\n",
       "      <td>BARITO dev'pmt addr'ss'd ELK scal'g iss'z by p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did GoTo Financial address technical chall...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nGoPay, as part of Indonesia’s tech...</td>\n",
       "      <td>GoTo Financial addressed technical challenges ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA AR...   \n",
       "1  How d'd BARITO dev'pmt addr'ss ELK scal'g iss'...   \n",
       "2  How did GoTo Financial address technical chall...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA A...   \n",
       "1  [<1-hop>\\n\\nH Ho ow w  w we e  b bu ui il lt t...   \n",
       "2  [<1-hop>\\n\\nGoPay, as part of Indonesia’s tech...   \n",
       "\n",
       "                                           reference persona_name query_style  \\\n",
       "0  The logging infrastructure was designed to sca...        Amina  MISSPELLED   \n",
       "1  BARITO dev'pmt addr'ss'd ELK scal'g iss'z by p...          NaN         NaN   \n",
       "2  GoTo Financial addressed technical challenges ...          NaN         NaN   \n",
       "\n",
       "  query_length                       synthesizer_name  \n",
       "0       MEDIUM  single_hop_specific_query_synthesizer  \n",
       "1          NaN   multi_hop_abstract_query_synthesizer  \n",
       "2          NaN   multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd13981-de96-4d81-b7d1-dedc57a05207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
